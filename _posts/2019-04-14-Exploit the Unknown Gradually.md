---
layout:     post
title:      Exploit the Unknown Gradually
subtitle:   One-Shot Video-Based Person Re-Identification by Stepwise Learning
date:       2019-04-14
author:     JoselynZhao
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - one-shot
    - Re-ID
    - SSL
---

**文章结构：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/2019033115414570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)

## Abstract
### 研究问题
one-shot learning for video-based person re-Identification (re-ID).
*用于基于视频的行人重识别的one-shot learning问题*

### 提出的方案
propose an approach to exploiting unla- beled tracklets by gradually but steadily improving the dis- criminative capability of the Convolutional Neural Network (CNN) feature representation via stepwise learning.
*文章提出了一种以逐步学习方式 逐渐且稳定地提高卷积神经网络（CNN）特征表示的判断能力。*

### 方案步骤
We first initialize a CNN model using one labeled tracklet for each identity. Then we update the CNN model by the following two steps iteratively:
	1. sample a few candidates with most reliable pseudo labels from unlabeled tracklets;
	2.  update the CNN model according to the selected data.
*首先用每个身份的带标记的轨迹来初始化CNN。*  ~~//得到θ？？？~~
*然后采用下面的这两个步骤来更新训练CNN。*
	*1、从未标记的轨迹中选中其伪标签置信度最高的部分 作为候选者。*
	*2、根据选择的数据来更新CNN*

### 创新点
- progressive sampling method *渐进采样方法*
 逐步增加所选择的伪标记候选者的数量。
- distance-based sampling criterion *基于距离的采样标准*
对比**分类评估**的采样标准


## 1 Introduction
### 现有方案和问题
依赖于大量的带标注样本（完全监督），但标注成本高
【 由此】提出半监督方法（semi-supervised methods），该方法示例[21][34].

### 基于视频的行人重识别的one-shot 问题的主要挑战
the label estimation for the abundant unlabeled tracklets
*对大量未标记的轨迹的标签估计*
【针对挑战】**典型的解决方案是：**
1. 首先为未标记的数据生成伪标签。
2. 初始标记数据和一些选定的伪标记的数据一起作为扩大的训练集。
3. 最后采用得到的训练集来重新训练识别模型。

【针对2.】现有方法多采用**静态策略(static strategy)**:
从头到尾选择固定大量的伪标记数据来扩大训练集。
【存在问题】初始模型可能不稳健，最终导致不可靠的预测。


### 本文核心方案
stepwise learning method EUG (Exploit the Unknown Gradually)*逐步学习方法EUG*
1. CNN模型在带标注的轨迹上进行初步训练。
2. 通过两个步骤迭代地更新CNN：**标签估计步骤**和**模型更新步骤**。

（同上文【方案步骤】）

#### 标签估计
为没有标注的轨迹生成伪标签，并根据预测可靠性选择一些标注了伪标记的轨迹用于训练。
根据**采样策略**，在迭代期间连续放大所选择的带伪标签数据的子集。~~（体现非静态）~~

#### 模型更新
在标记数据和采样的带伪标记的数据子集上重新训练CNN模型。

### 与[21][34]不同
1. EUG的标签估计，开始的时候选用的是非常少量的 带伪标签的数据加入训练。
2. 这部分带伪标签的数据拥有较高的可靠性（置信度）。
3. 再后面的迭代中，逐步加入更多的带伪标签的数据。

*（即渐进采样策略）*

### 渐进采样策略（progressive sampling strategy）
【特点】
1. 以更保守的方式（以较慢的速度）放大采样的带伪标记数据子集
2. 该模型可以获得更好的性能

（**采样标准**极大地影响了所提方法的性能，**基于距离的采样标准**比**分类评估的采样标准**更好）


### 文章贡献
1. 提出了一种基于视频的人物重定义的渐进方法EUG，以更好地利用未标记的数据（tracklets）。
2. 采用**基于距离的采样标准**进行标签估计和候选选择，以显着提高标签估计的性能。

## 2. Related Works
[21][34]
**one-shot**：每个标注对应的样本只有一个。

## 3. The Progressive Model
### 3.1. Preliminaries
带标签的数据集 $L = \left\{(x_1,y_1),...,(x_{n_l},y_{n_l})\right\}$
不带标签的数据集 $U = \left\{(x_{n_l+1}),...,(x_{n_l+n_u})\right\}$
$|L| = n_l$
$|U| = n_u$
#### 初步目标函数
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401114311165.png)
$\phi$用以提取$x_i$的特征, $f$用以生成预测标签结果，$l$是预测结果和正确标签$y_i$之间的损失表示。
**目标**即是求得使公式（1）结果最小值时的$\phi和\omega$。

#### 考虑伪标签的目标函数
![在这里插入图片描述](https://img-blog.csdnimg.cn/201904011425500.png)
$yˆ_i$是伪标签，$s_i$是未标记样本$x_i$的选择指示符，其决定着在更新训练CNN时是否采用带伪标签数据$(x_i,y_i)$.

### 3.2. Framework Overview
#### 公式（2）的求解方案
we first optimize $\phi$ and $\omega$ and then optimize yˆ and s, i.e., the model updating and the label estimating.
*我们首先优化 $\phi$ 和 $\omega$ ，然后优化yˆ和s，即模型更新和标签估计。*

$$a^i+b_3=c$$
在测试$a^i+b_3=c$公式，看是否能够正确显示。

**选定的伪标签候选者的集合S**如下：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401143452766.png)

#### 框架描述
1. 在**标记数据集 L** 上训练初始模型。
2. 使用初始模型来预测未标记数据对应的伪标记yˆ。根据**标签可靠性评估标准**，我们生成选择指标s，根据公式（3）来进行筛选。
3.  在模型更新步骤中，将**选定的伪标签候选者的集合S**与初始**标记数据集合L**一起视为新训练集合D。集合D将用于重新训练模型以便使模型更健壮。在训练迭代期间，每个步骤中的候选集S被连续地扩展。 通过这种方式，就可以逐步学习更稳定的模型。

（同上述【方案步骤】和【本文核心方案】）
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401151152141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**图解：**
- 不同颜色代表不同的身份样本。
- 最初使用带标注的ont-shot数据训练CNN模型。
- 对于每次迭代：
4. 根据特征空间中的距离选择最可靠的带伪标签的未标记样本
5. 通过**带标注数据**和候选的**可靠的带伪标签数据**来更新CNN模型，逐渐扩大候选者的范围。
6. 对于轨迹，每个帧特征首先由CNN模型提取，然后在时间上平均化为轨迹特征（时间平均池）。

### 3.3. Progressive and Effective Sampling Strategy
**现有策略及其存在的问题：**

【静态策略】在初始迭代中，将过多的伪标记数据合并到训练中是不合理的。
【分类评估】分类器可能很容易过度拟合one-shot数据，并且可能无法学习类别间的内在区别。 因此，对于没有出现过的类别，分类预测可能不可靠。

**本文针对现有策略及其存在的问题提出解决方法：**
1. 采用动态采样策略，即**渐进采样策略**，逐步增加所选择的伪标签数据的数量;
2. 采用更加有效的采样标准，即**基于距离的采样标准**，它以特征空间中的欧几里得距离作为可靠性的度量。

#### 采样标准详解
通过特征空间中最近的标记邻居，给每个未标记数据分配标签。
**标签估计的置信度**定义为未标记数据与其最近标记邻居之间的距离。
**候选者选择**，则根据他们的**标签估计置信度**选择一些最可靠的伪标记数据。

**距离偏差的计算：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401153207118.png)
每个未标记数据的伪标签与和它距离最最近的带标签的数据的标签相同。
公式（4）中的距离是样本在特征空间中的欧几里得距离。


**候选伪标签的选择：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401153438330.png)
$m_t$是伪标签样本量。
$s_t$是候选指示集。公式（5）求使得$s_t$最小的$s_i$，即在所有的伪标签数据里面选出$m_t$个候选样本，并令其对应的$s_i$为1。

#### 算法流程
**扩大因子P：**
P决定了迭代期间扩大候选集的速度。
【P的设定】
较小的P可是使性能稳定增长，并最终实现良好的性能。
缺点是可能需要过多的阶段才能获得很好的性能。
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401152919912.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**输入：**
带标记数据L，未标记数据U，膨胀因子$P\in(0,1)$, $\theta _0$初始化了的CNN模型。
**输出：**
最佳CNN模型的参数$\theta^*$.
**流程：**
1. 初始化。
2. 循环begin。终止条件是$m_t>|U|$.
即伪标签数据已全部加入训练。
3. 更新训练时间步t
4. 更新训练集$D_t$。
5. 基于训练集$D_t$训练CNN模型
6. 根据公式（5）生成候选指示集$s_t$.
7. 根据公式（3）和候选指示集$s_t$更新
选定的伪标签候选者集合$S_t$.
9. 根据公式更新采样数量$m_{t+1}$
10. 循环end。

  10-15.遍历每一个时间步，在验证集上评估 $\theta_i$, 得到其性能$V_i$. 找出最佳性能$V^*$及其对应的$\theta^*$。

 ## 4. Experiments
 ### 4.1. Datasets and Settings
- The MARS dataset
- DukeMTMC-VideoReID

**评估指标：**

- Cumulative Matching Characteristic (CMC) curve
- mean average precision (mAP)

### 4.2. Comparison with the State-of-the-Art Methods
**实验结果：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/201904011650007.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**解释：**
- 所有方法都是基于相同的主干模型ETAP-Net进行的
- Baseline（one-shot）：仅在标记数据上训练的初始模型。
- Baseline（supervised）：100％带标注的完全监督训练数据的上限。

### 4.3. Algorithm Analysis
#### 采样标准分析
**分类评估采样标准**和**基于距离采样标准**的**标签估计**和**评估性能**如图3和表2所示。

**图3：**
![图3](https://img-blog.csdnimg.cn/20190401165428402.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**解释：**
当放大系数p = 0.1时，与MARS的两个采样标准进行比较。
两个采样标准在开始阶段达到相似的高精度。
（a）和（b）是精确度随候选伪标签样本量的变化曲线。
（c）和（d）分别是Rank-1准确度和mAP。 每个实心点表示迭代步骤。
**表2:**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401165504431.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**解释：**
表2显示了两个标准与**不同扩大因子P**的评估性能差异。
结果表明在各个p下，**基于距离的采样标准**总是更优。


#### 迭代分析
**图4：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401170246927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**解释：**
图4说明了迭代过程中的**标签估计性能**和**评估性能**。
在初始迭代中，所选子集（蓝线）的伪标签的精度相对较高，因为EUG仅采用一些最可靠的样本。
在后期阶段，随着EUG逐渐采用更加困难和多样化的样品，精度随着呼叫（红线）的增加而下降。尽管精度下降，但标签估计的F分数（绿线）仍在不断增加。
在整个迭代过程中，所有未标记数据（橙色线）的伪标签估计精度从29.8％持续增加到54.96％，这表明模型稳定增长稳健。
在最后几次迭代中，评估性能停止增加，因为添加新样本的增益被过度伪标签错误的丢失所抵消。

#### 扩大因子分析
1. 以较慢的速度扩大选定的集合，模型总能获得更好的性能
2. 曲线之间的间隙，显示了迭代期间累积的估计误差。

**图5：**
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190401170726774.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L05HVWV2ZXIxNQ==,size_16,color_FFFFFF,t_70)
**解释：**
“EF”表示放大因子。
 x轴伪标签样本占比。
 每个实心点表示迭代步骤。
 结果显示，较低的扩大因子有利于提高性能。

## 5. Conclusion
【挑战】one-shot挑战是伪标签不够可靠，这阻止了训练模型提高稳健性。
【解决方案】提出了一种动态采样策略，从简单可靠的伪标签样本开始，逐步增量来更新模型。
【实验结果】以较慢的速度扩大所选择的伪标签样本，该模型可以获得更好的性能。【抽样标准】基于距离的采样标准 显著提高了标签估计的性能。


## 批判性思维点
1. $m_t的更新$
2. $循环放入$
3. $排除错误伪标签$



















